{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81368f4f",
   "metadata": {
    "id": "81368f4f"
   },
   "source": [
    "- **Machine learning applications on text classification for companies**\n",
    "\n",
    "The dataset that will be worked on is called \"TCC.xlsx\" and contains the information of the requirements, requests and petitions presented to the company SIGMA Ingenier√≠a S.A of Manizales in the technical support area. \n",
    "\n",
    "The fields that will be taken into account for this work will be \"description\" and \"category\", the idea is to find the best performance technique in the classification of descriptions to implement in the company and perform the automatic classification of future requirements, it is intended that Through the predicted category, the protocols of solution to the request presented by the client are provided to offer a better quality in the response and also, reduce the time in the response by the service area and technical support of the company towards the client. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f6332",
   "metadata": {
    "id": "c00f6332"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Y7FdNdVMbNWy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7FdNdVMbNWy",
    "outputId": "05eb1e78-ab02-4438-a49b-0951768d2d40",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Classification Methods\n",
    "from sklearn import svm\n",
    "\n",
    "#NLP\n",
    "import nltk \n",
    "nltk.download('stopwords') \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "import spacy \n",
    "import es_core_news_sm\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# from yellowbrick.classifier import ClassificationReport \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Tools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from scipy.sparse import csr_matrix \n",
    "import string \n",
    "import time as tm\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import joblib\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57a999",
   "metadata": {
    "id": "8b57a999"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b8f3a2c",
   "metadata": {
    "id": "2b8f3a2c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def lemmatizer(text):  \n",
    "    doc = nlp(text)\n",
    "    return ' '.join([word.lemma_ for word in doc]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5089191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance_over_sampling(features, labels, HO=False, CV=True, methods_list=[\"SMOTE\"]):\n",
    "    \n",
    "    best_acc=list()\n",
    "    for method in methods_list:\n",
    "        if method == \"RandomOverSampler\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=8, stratify=labels)\n",
    "            sampler = RandomOverSampler(random_state=21) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        elif method == \"SMOTE\":\n",
    "            print(method)\n",
    "#             print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=8, stratify=labels)\n",
    "            sampler = SMOTE(random_state=21,n_jobs=-1) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "#             print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "#             print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "\n",
    "        elif method == \"SMOTEN\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=8, stratify=labels)\n",
    "            sampler = SMOTEN(random_state=21,n_jobs=-1)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        elif method == \"ADASYN\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=8, stratify=labels)\n",
    "            sampler = ADASYN(random_state=21,n_jobs=-1) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        elif method == \"BorderlineSMOTE\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=8, stratify=labels)\n",
    "            sampler = BorderlineSMOTE(random_state=21,n_jobs=-1) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        elif method == \"KMeansSMOTE\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=8, stratify=labels)\n",
    "            sampler = KMeansSMOTE(random_state=21,n_jobs=-1, k_neighbors=np.unique(y_test).shape[0]) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        elif method == \"SVMSMOTE\":\n",
    "            print(method)\n",
    "            print(\"originals labels unique: \",np.unique(labels, return_counts=True)) \n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                                                                test_size=0.20, random_state=8, stratify=labels)\n",
    "            sampler = SVMSMOTE(random_state=21,n_jobs=-1) \n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)             \n",
    "            print(\"y_train labels unique:   \",np.unique(y_train, return_counts=True))\n",
    "            print(\"y_test labels unique:    \",np.unique(y_test, return_counts=True)) \n",
    "            classifier_metrics(X_train,X_test,y_train,y_test,HO=HO,CV=CV)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7cc9b56",
   "metadata": {
    "id": "f7cc9b56"
   },
   "outputs": [],
   "source": [
    "def classifier_metrics(X_train,X_test,y_train,y_test,HO=True,CV=False):    \n",
    "    def metrics(model):\n",
    "        print(\"\\nHold-Out in process...\")\n",
    "        start_time = tm.time()\n",
    "        model.fit(X_train, y_train) \n",
    "        \n",
    "        model_filename = \"Modelo_SVM_V4.sav\" # name given to th trained model\n",
    "        joblib.dump(classifier, model_filename) # Save the model\n",
    "        print('Model is saved into to disk successfully Using Job Lib')\n",
    "        \n",
    "        \n",
    "        TIME = tm.time() - start_time \n",
    "        print(\"Time, Training: {0:.4f} [seconds]\".format(TIME))\n",
    "        start_time = tm.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        TIME = tm.time() - start_time \n",
    "        print(\"Time, Prediction: {0:.4f} [seconds]\".format(TIME))\n",
    "        accuracy_s  = accuracy_score(y_test,y_pred) \n",
    "        f1_s        = f1_score(y_test,y_pred,average='weighted')\n",
    "        recall_s    = recall_score(y_test,y_pred,average='weighted')\n",
    "        precision_s = precision_score(y_test,y_pred,average='weighted')\n",
    "        print('accuracy_score: {0:.4f}'.format(accuracy_s))\n",
    "        print('f1_score: {0:.4f}'.format(f1_s))\n",
    "        print('recall_score: {0:.4f}'.format(recall_s))\n",
    "        print('precision_score: {0:.4f}'.format(precision_s))\n",
    "        print ('\\n clasification report:\\n', classification_report(y_test, y_pred, digits = 4))\n",
    "        print('\\nCross-Validation in process...')\n",
    "        start_time = tm.time() \n",
    "        kfold = model_selection.KFold(n_splits=10)\n",
    "        y_CV = np.concatenate((y_train,y_test))\n",
    "        if \"GaussianNB\" in str(name) or \"LinearDiscriminantAnalysis\" in str(name):\n",
    "            X_CV = np.concatenate((X_train,X_test))\n",
    "            cv_results = np.array(model_selection.cross_val_score(model, X_CV, y_CV, cv=kfold, scoring='accuracy', n_jobs=-1))\n",
    "        else:\n",
    "            X_CV = np.concatenate((X_train.toarray(),X_test.toarray()))\n",
    "            X_CV = csr_matrix(X_CV)\n",
    "            cv_results = np.array(model_selection.cross_val_score(model, X_CV, y_CV, cv=kfold, scoring='accuracy', n_jobs=-1))\n",
    "        \n",
    "        cv_results = cv_results[np.logical_not(np.isnan(cv_results))] \n",
    "        TIME = tm.time() - start_time \n",
    "        print(\"Time, CV: {0:.4f} [seconds]\".format(TIME))\n",
    "        print('CV: {0:.4f} {1:.4f}'.format(cv_results.mean(),cv_results.std()))\n",
    "\n",
    "    for name in classifier:\n",
    "        print (\"---------------------------------------------------------------------------------\\n\") \n",
    "        print(str(name))\n",
    "        if \"GaussianNB\" in str(name) or \"LinearDiscriminantAnalysis\" in str(name):\n",
    "            X_train=csr_matrix(X_train) \n",
    "            X_test =csr_matrix(X_test) \n",
    "            X_train=X_train.toarray() \n",
    "            X_test=X_test.toarray() \n",
    "        else:\n",
    "            X_train=csr_matrix(X_train)\n",
    "            X_test=csr_matrix(X_test)\n",
    "            \n",
    "        metrics(name)\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62aed031",
   "metadata": {
    "id": "62aed031"
   },
   "outputs": [],
   "source": [
    "path_figures = \"../images\"\n",
    "if not os.path.exists(path_figures):\n",
    "    os.makedirs(path_figures)\n",
    "\n",
    "# Classification report\n",
    "def CR_viz():\n",
    "    ax = plt.figure(figsize=(15,20)) \n",
    "    visualizer = ClassificationReport(model_selected, classes=classes, support=True,  \n",
    "                                      cmap='Blues', title=\"Classification Report - \"+model_name)\n",
    "    visualizer.fit(X_train, y_train)   \n",
    "    visualizer.score(X_test, y_test)      \n",
    "    visualizer.poof()\n",
    "    ax.show()\n",
    "    ax.savefig(path_figures+\"/\"+model_name+\"_CR\"+\".pdf\", bbox_inches = \"tight\") \n",
    "\n",
    "# Confusion matrix\n",
    "def CM_viz():\n",
    "    model_selected.fit(X_train, y_train) \n",
    "    y_pred = model_selected.predict(X_test) \n",
    "    conf = confusion_matrix(y_test, y_pred) \n",
    "    plt.figure(figsize=(42 , 42)) \n",
    "    annot_kws={'fontsize':20, 'verticalalignment':'center' }\n",
    "    ax = sns.heatmap(conf, annot=True, cmap='Blues',fmt = 'd',annot_kws= annot_kws, xticklabels=np.unique(y_test), yticklabels=np.unique(y_test)) \n",
    "    ax.set(title=\"Confusion Matrix with labels\", xlabel=\"Predicted Values\", ylabel=\"Actual Values\")\n",
    "    sns.set(font_scale=2)\n",
    "    plt.title(\"Confusion Matrix - \"+model_name, fontsize = 35)\n",
    "    plt.xlabel(\"Predicted Values\", fontsize = 35)\n",
    "    plt.ylabel(\"Actual Values\", fontsize = 35)\n",
    "    plt.savefig(path_figures+\"/\"+model_name+\"_CM\"+\".pdf\", bbox_inches = \"tight\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb6e59",
   "metadata": {
    "id": "a8fb6e59"
   },
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mQdXPilDs7Cj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "mQdXPilDs7Cj",
    "outputId": "70e31e3e-e25c-4fce-b97c-3c391b114650",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tik_codigo</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TIK7201</td>\n",
       "      <td>En Seguimiento documental de Autos hay un camp...</td>\n",
       "      <td>Duda en uso de campos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIK8740</td>\n",
       "      <td>no se muestra nombre de ruta solo muestra n√∫me...</td>\n",
       "      <td>Duda en uso de campos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIKS01</td>\n",
       "      <td>Para que sirve el campo que aparece en el reporte</td>\n",
       "      <td>Duda en uso de campos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TIKS02</td>\n",
       "      <td>No entiendo a que se refiere el campo 2 del mo...</td>\n",
       "      <td>Duda en uso de campos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TIKS03</td>\n",
       "      <td>El campo 5 en la plataforma de corpo para que ...</td>\n",
       "      <td>Duda en uso de campos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TIK11427</td>\n",
       "      <td>No definido: Actividades de mercadeo</td>\n",
       "      <td>0- No definido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TIK11485</td>\n",
       "      <td>No definido: Eliminar los expedientes OOCA-001...</td>\n",
       "      <td>0- No definido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TIK11441</td>\n",
       "      <td>No definido: Construcci√≥n de informe mensual P...</td>\n",
       "      <td>0- No definido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>TIK10979</td>\n",
       "      <td>No definido: Planeaci√≥n del proyecto Desarroll...</td>\n",
       "      <td>0- No definido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>TIK11489</td>\n",
       "      <td>No definido: Priorizaci√≥n √Årea de Marca</td>\n",
       "      <td>0- No definido</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2146 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tik_codigo                                        descripcion  \\\n",
       "0       TIK7201  En Seguimiento documental de Autos hay un camp...   \n",
       "1       TIK8740  no se muestra nombre de ruta solo muestra n√∫me...   \n",
       "2        TIKS01  Para que sirve el campo que aparece en el reporte   \n",
       "3        TIKS02  No entiendo a que se refiere el campo 2 del mo...   \n",
       "4        TIKS03  El campo 5 en la plataforma de corpo para que ...   \n",
       "...         ...                                                ...   \n",
       "2141   TIK11427               No definido: Actividades de mercadeo   \n",
       "2142   TIK11485  No definido: Eliminar los expedientes OOCA-001...   \n",
       "2143   TIK11441  No definido: Construcci√≥n de informe mensual P...   \n",
       "2144   TIK10979  No definido: Planeaci√≥n del proyecto Desarroll...   \n",
       "2145   TIK11489            No definido: Priorizaci√≥n √Årea de Marca   \n",
       "\n",
       "                  categoria  \n",
       "0     Duda en uso de campos  \n",
       "1     Duda en uso de campos  \n",
       "2     Duda en uso de campos  \n",
       "3     Duda en uso de campos  \n",
       "4     Duda en uso de campos  \n",
       "...                     ...  \n",
       "2141         0- No definido  \n",
       "2142         0- No definido  \n",
       "2143         0- No definido  \n",
       "2144         0- No definido  \n",
       "2145         0- No definido  \n",
       "\n",
       "[2146 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Dataset\n",
    "filename = '../Data/TCC_NEW_V2.xlsx'\n",
    "DataSet0 = pd.read_excel(os.path.join(filename), engine='openpyxl')\n",
    "DataSet0.shape \n",
    "DataSet0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea0b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We eliminate the NaN or empty data present in the columns to work\n",
    "PorBorrar1 = DataSet0[DataSet0['descripcion'].isnull()].index\n",
    "DataSet0=DataSet0.drop(PorBorrar1, axis=0).reset_index(drop = True)\n",
    "PorBorrar1 = DataSet0[DataSet0['categoria'].isnull()].index\n",
    "DataSet0=DataSet0.drop(PorBorrar1, axis=0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65853643",
   "metadata": {
    "id": "65853643"
   },
   "source": [
    "# Best Machine learning application (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616077d2",
   "metadata": {
    "id": "616077d2"
   },
   "source": [
    "## 4. Dataset with Preprocessing and Balancing, Optimization of parameters (DPBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8698e05",
   "metadata": {
    "id": "d8698e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert texts to lowercase\n",
    "DataSet0['descripcion'] = DataSet0['descripcion'].str.lower()\n",
    "DataSet0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98a8cb57",
   "metadata": {
    "id": "98a8cb57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation marks\n",
    "punct = string.punctuation\n",
    "\n",
    "for c in punct:\n",
    "    for fila in range(len(DataSet0)):\n",
    "        DataSet0['descripcion'][fila] = DataSet0['descripcion'][fila].replace(c, \" \")\n",
    "DataSet0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd664f2d",
   "metadata": {
    "id": "bd664f2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply stemming to the description field\n",
    "DataSet0['descripcion'] = DataSet0['descripcion'].apply(lambda x: lemmatizer(x)) \n",
    "DataSet0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "525895a7",
   "metadata": {
    "id": "525895a7"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "'X' and 'y' are defined, 'X' will be in charge of containing the characteristics of the dataset that for this case\n",
    "is the description that will define the category to which it belongs and 'y' contains the values of the labels, \n",
    "in this case of the possible categories defined.\n",
    "'''\n",
    "\n",
    "X = DataSet0['descripcion'] \n",
    "y = DataSet0['categoria'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c43efd1f",
   "metadata": {
    "id": "c43efd1f"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Bearing in mind that the problem worked consists of text, it is necessary to transform them and prepare them for \n",
    "later use, in this case, each of the words contained in the description will be encoded in floating point values \n",
    "for use in machine learning algorithms, this process is also known as feature extraction or vectorization \n",
    "using the TfidfVectorizer library\n",
    "'''\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words=stopwords.words(\"spanish\"))\n",
    "X = vectorizer.fit_transform(X) \n",
    "\n",
    "# Save word dictionary created by TfidfVectorizer\n",
    "pickle.dump(vectorizer.vocabulary_,open(\"Features_SVM_V4.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab2f0f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "SVC()\n",
      "\n",
      "Hold-Out in process...\n",
      "Model is saved into to disk successfully Using Job Lib\n",
      "Time, Training: 0.6902 [seconds]\n",
      "Time, Prediction: 0.0630 [seconds]\n",
      "accuracy_score: 0.8884\n",
      "f1_score: 0.8892\n",
      "recall_score: 0.8884\n",
      "precision_score: 0.9098\n",
      "\n",
      " clasification report:\n",
      "                                                            precision    recall  f1-score   support\n",
      "\n",
      "                                           0- No definido     1.0000    1.0000    1.0000        12\n",
      "                                   1- Nuevo requerimiento     1.0000    1.0000    1.0000        13\n",
      "        Adici√≥n o modificaci√≥n de funcionalidad en perfil     0.7500    0.9000    0.8182        10\n",
      "                                    Auditoria del sistema     1.0000    0.4444    0.6154         9\n",
      "                            Calculo erroneo en formulario     0.9231    1.0000    0.9600        12\n",
      "                                     Cambiar datos por BD     1.0000    0.9000    0.9474        10\n",
      "                   Capacitacion de modulo o funcionalidad     0.9167    0.7857    0.8462        14\n",
      "                                    Carga de datos masiva     1.0000    0.9412    0.9697        17\n",
      "                     Configuracion de nueva capa en visor     1.0000    1.0000    1.0000         6\n",
      "                   Configuracion de nuevo widget en visor     1.0000    1.0000    1.0000         7\n",
      "                           Configuraci√≥n de equipos (GPS)     1.0000    0.9286    0.9630        14\n",
      "                           Configuraci√≥n de nuevo Reporte     0.8333    0.5000    0.6250        10\n",
      "                             Configuraci√≥n de nuevo campo     1.0000    0.7143    0.8333         7\n",
      "             Creaci√≥n de usuarios para ingreso plataforma     1.0000    0.7778    0.8750         9\n",
      "                                     Datos erroneos en BI     1.0000    0.8750    0.9333         8\n",
      "                                   Datos erroneos en Cubo     1.0000    1.0000    1.0000         8\n",
      "                                  Datos erroneos en Visor     1.0000    0.8571    0.9231         7\n",
      "                                Datos erroneos en reporte     0.8750    0.7778    0.8235         9\n",
      "                  Disminucion del desempe√±o de plataforma     0.8750    0.7000    0.7778        10\n",
      "                                    Duda en uso de campos     1.0000    0.8571    0.9231         7\n",
      "                                Duda en uso de plataforma     0.6667    0.8571    0.7500         7\n",
      "           Formulario no guarda, no edita y o no elimina      0.9000    1.0000    0.9474         9\n",
      "                                      Generaci√≥n de shape     1.0000    1.0000    1.0000        11\n",
      "Generar reporte, informe, datos solicitado por el cliente     1.0000    0.8000    0.8889        10\n",
      "                Implantaci√≥n m√≥dulo o nueva funcionalidad     0.8000    1.0000    0.8889        12\n",
      "                      Imposibilidad ingreso de un usuario     0.8235    0.9333    0.8750        15\n",
      "            Interrupci√≥n del servicio/No carga el sistema     0.7778    0.9333    0.8485        15\n",
      "                                     Lentitud en el visor     0.8889    1.0000    0.9412         8\n",
      "                         No busca ni filtra en formulario     0.8571    0.8571    0.8571         7\n",
      "                                        No carga el visor     1.0000    1.0000    1.0000        14\n",
      "                                   No carga un formulario     0.7778    0.7000    0.7368        10\n",
      "                                      No descarga reporte     0.5294    0.9474    0.6792        19\n",
      "                   No envia el backup de aplicaci√≥n movil     1.0000    0.8889    0.9412         9\n",
      "               No funciona adecuadamente widget del visor     1.0000    0.8889    0.9412         9\n",
      "                 No inicia sesion un usuario en movilidad     1.0000    0.7143    0.8333         7\n",
      "                                         No transmite GPS     0.7692    0.9091    0.8333        11\n",
      "                          Publicaci√≥n de servicios, capas     0.9000    1.0000    0.9474         9\n",
      "                                    Revisi√≥n de Consultas     0.9000    1.0000    0.9474         9\n",
      "                                          Revisi√≥n de GPS     0.9167    0.7857    0.8462        14\n",
      "                             Saltos de GPS (Descalibrado)     1.0000    0.9444    0.9714        18\n",
      "                Subir aplicaci√≥n m√≥vil (app) a play store     1.0000    1.0000    1.0000         8\n",
      "\n",
      "                                                 accuracy                         0.8884       430\n",
      "                                                macro avg     0.9190    0.8809    0.8904       430\n",
      "                                             weighted avg     0.9098    0.8884    0.8892       430\n",
      "\n",
      "\n",
      "Cross-Validation in process...\n",
      "Time, CV: 1.1953 [seconds]\n",
      "CV: 0.9602 0.0339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ML Models CON TCC_NEW_V2\n",
    "classifier=[svm.SVC(C=1000000, gamma=0.000001, kernel = 'rbf')\n",
    "            ] \n",
    "\n",
    "methods_list=[\"SMOTE\"\n",
    "             ]\n",
    "             \n",
    "# class_balance_over_sampling(features, labels, HO=True, CV=False, methods_list=methods_list)\n",
    "class_balance_over_sampling(X, y, HO=True, CV=False, methods_list=methods_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "016a6532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingrese la descripci√≥n del Ticket: \n",
      "NoneNuevo requerimiento: se pide realizar estudio de mercadeo \n",
      " El ticket ingresado es: Nuevo requerimiento: se pide realizar estudio de mercadeo \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['1- Nuevo requerimiento'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we load the model and verify its performance by making a prediction \n",
    "\n",
    "model_filename = \"Modelo_SVM_V4.sav\"\n",
    "\n",
    "my_model = joblib.load(model_filename)\n",
    "\n",
    "Descripcion_ticket = input(print(\"Ingrese la descripci√≥n del Ticket: \")) # configuracion de GPS para Palmira\n",
    "print(f\" El ticket ingresado es: {Descripcion_ticket}\")\n",
    "\n",
    "Prediccion = my_model[0].predict(vectorizer.transform([Descripcion_ticket]))\n",
    "\n",
    "Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c306e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Machine learning A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
